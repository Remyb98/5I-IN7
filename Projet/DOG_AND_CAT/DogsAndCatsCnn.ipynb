{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3db7456-55f8-41b2-8990-9bf752d244cb",
   "metadata": {},
   "source": [
    "# Import des librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c2c5c61f-9bb6-4a69-8744-4ca98f3f2aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39912846-dc98-4591-a78e-000418a2bc16",
   "metadata": {},
   "source": [
    "# Chargement des photos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "54fe4b39-2bae-4328-b478-c5b98882a9b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = \"dataset/training_set/\"\n",
    "test_path = \"dataset/test_set/\"\n",
    "classes = os.listdir(train_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "755d75f3-6aa2-4927-a452-050c4988849a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cats', 'dogs']\n"
     ]
    }
   ],
   "source": [
    "print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3641bad2-6c93-4174-9060-dc8c73dbc8d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialising the CNN\n",
    "classifier = Sequential([\n",
    "    Conv2D(32, (3, 3), input_shape = (64, 64, 3), activation = 'relu'), # Step 1 - Convolution\n",
    "    MaxPooling2D(pool_size = (2, 2)), # Step 2 - Pooling\n",
    "    Conv2D(32, (3, 3), activation = 'relu'), # Adding a second convolutional layer\n",
    "    MaxPooling2D(pool_size = (2, 2)),\n",
    "    Flatten(), # Step 3 - Flattening\n",
    "    Dense(units = 128, activation = 'relu'), # Step 4 - Full connection\n",
    "    Dense(units = 1, activation = 'sigmoid')\n",
    "])\n",
    "\n",
    "\n",
    "# Compiling the CNN\n",
    "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "76a8ea42-c8ec-48ba-b6e0-e744cb9f00d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale = 1./255, shear_range = 0.2, zoom_range = 0.2, horizontal_flip = True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "58922c1f-8b02-4aeb-8658-a14e1d03d7d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8000 images belonging to 2 classes.\n",
      "Found 2000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "training_set = train_datagen.flow_from_directory(train_path,\n",
    "                                                 target_size = (64, 64),\n",
    "                                                 batch_size = 32,\n",
    "                                                 class_mode = 'binary')\n",
    "\n",
    "test_set = test_datagen.flow_from_directory(test_path,\n",
    "                                            target_size = (64, 64),\n",
    "                                            batch_size = 32,\n",
    "                                            class_mode = 'binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "215831eb-dd0e-4381-ad6e-67857e999fb9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "250/250 [==============================] - 26s 103ms/step - loss: 0.4194 - accuracy: 0.8062 - val_loss: 0.4939 - val_accuracy: 0.7765\n",
      "Epoch 2/20\n",
      "250/250 [==============================] - 26s 103ms/step - loss: 0.4060 - accuracy: 0.8123 - val_loss: 0.4979 - val_accuracy: 0.7690\n",
      "Epoch 3/20\n",
      "250/250 [==============================] - 25s 99ms/step - loss: 0.4070 - accuracy: 0.8100 - val_loss: 0.4645 - val_accuracy: 0.7915\n",
      "Epoch 4/20\n",
      "250/250 [==============================] - 26s 105ms/step - loss: 0.3933 - accuracy: 0.8214 - val_loss: 0.4600 - val_accuracy: 0.7910\n",
      "Epoch 5/20\n",
      "250/250 [==============================] - 27s 110ms/step - loss: 0.3867 - accuracy: 0.8257 - val_loss: 0.4925 - val_accuracy: 0.7850\n",
      "Epoch 6/20\n",
      "250/250 [==============================] - 26s 104ms/step - loss: 0.3750 - accuracy: 0.8281 - val_loss: 0.4667 - val_accuracy: 0.8040\n",
      "Epoch 7/20\n",
      "250/250 [==============================] - 24s 97ms/step - loss: 0.3706 - accuracy: 0.8316 - val_loss: 0.5268 - val_accuracy: 0.7735\n",
      "Epoch 8/20\n",
      "250/250 [==============================] - 23s 91ms/step - loss: 0.3606 - accuracy: 0.8369 - val_loss: 0.4911 - val_accuracy: 0.7920\n",
      "Epoch 9/20\n",
      "250/250 [==============================] - 21s 85ms/step - loss: 0.3487 - accuracy: 0.8416 - val_loss: 0.4810 - val_accuracy: 0.7925\n",
      "Epoch 10/20\n",
      "250/250 [==============================] - 22s 86ms/step - loss: 0.3416 - accuracy: 0.8462 - val_loss: 0.4715 - val_accuracy: 0.8105\n",
      "Epoch 11/20\n",
      "250/250 [==============================] - 23s 91ms/step - loss: 0.3350 - accuracy: 0.8457 - val_loss: 0.4674 - val_accuracy: 0.8090\n",
      "Epoch 12/20\n",
      "250/250 [==============================] - 22s 86ms/step - loss: 0.3333 - accuracy: 0.8512 - val_loss: 0.4602 - val_accuracy: 0.8090\n",
      "Epoch 13/20\n",
      "250/250 [==============================] - 21s 84ms/step - loss: 0.3202 - accuracy: 0.8616 - val_loss: 0.4515 - val_accuracy: 0.8135\n",
      "Epoch 14/20\n",
      "250/250 [==============================] - 21s 84ms/step - loss: 0.3098 - accuracy: 0.8661 - val_loss: 0.4831 - val_accuracy: 0.8140\n",
      "Epoch 15/20\n",
      "250/250 [==============================] - 21s 84ms/step - loss: 0.3081 - accuracy: 0.8646 - val_loss: 0.4747 - val_accuracy: 0.8075\n",
      "Epoch 16/20\n",
      "250/250 [==============================] - 21s 84ms/step - loss: 0.2911 - accuracy: 0.8727 - val_loss: 0.4690 - val_accuracy: 0.8100\n",
      "Epoch 17/20\n",
      "250/250 [==============================] - 22s 88ms/step - loss: 0.2945 - accuracy: 0.8717 - val_loss: 0.4838 - val_accuracy: 0.8010\n",
      "Epoch 18/20\n",
      "250/250 [==============================] - 22s 88ms/step - loss: 0.2779 - accuracy: 0.8820 - val_loss: 0.4981 - val_accuracy: 0.8065\n",
      "Epoch 19/20\n",
      "250/250 [==============================] - 22s 88ms/step - loss: 0.2708 - accuracy: 0.8844 - val_loss: 0.5140 - val_accuracy: 0.7930\n",
      "Epoch 20/20\n",
      "250/250 [==============================] - 22s 88ms/step - loss: 0.2811 - accuracy: 0.8808 - val_loss: 0.5132 - val_accuracy: 0.8010\n"
     ]
    }
   ],
   "source": [
    "history = classifier.fit(training_set, epochs = 20, validation_data = test_set, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eafaef0-30af-484c-932c-c79fad362fb0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
